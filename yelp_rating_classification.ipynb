{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Description of the data:**\n",
    "\n",
    "- **`yelp.csv`** contains the dataset. \n",
    "- Each observation (row) in this dataset is a review of a particular business by a particular user.\n",
    "- The **stars** column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n",
    "- The **text** column is the text of the review.\n",
    "\n",
    "**Goal:** Predict the star rating of a review using **only** the review text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Read yelp.csv into a pandas DataFrame and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path = 'data/yelp.csv'\n",
    "yelp_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id    object\n",
       "date           object\n",
       "review_id      object\n",
       "stars           int64\n",
       "text           object\n",
       "type           object\n",
       "user_id        object\n",
       "cool            int64\n",
       "useful          int64\n",
       "funny           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'date', 'review_id', 'stars', 'text', 'type', 'user_id',\n",
       "       'cool', 'useful', 'funny'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Creating a new DataFrame that only contains the **5-star** and **1-star** reviews.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_5_or_1_star = yelp_df.loc[(yelp_df['stars']==1) | (yelp_df['stars']==5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_5_or_1_star.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3337\n",
       "1     749\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_5_or_1_star['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Define X and y from the new DataFrame, and then split X and y into training and testing sets, using the **review text** as the only feature and the **star rating** as the response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp_5_or_1_star['text']\n",
    "y = yelp_5_or_1_star['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khyati\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064,)\n",
      "(1022,)\n",
      "(3064,)\n",
      "(1022,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Use CountVectorizer to create **document-term matrices** from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '00a',\n",
       " '00am',\n",
       " '00pm',\n",
       " '01',\n",
       " '02',\n",
       " '03',\n",
       " '03342',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '09',\n",
       " '0buxoc0crqjpvkezo3bqog',\n",
       " '0l',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1000x',\n",
       " '1001',\n",
       " '100th',\n",
       " '101',\n",
       " '102',\n",
       " '105',\n",
       " '1070',\n",
       " '108',\n",
       " '10am',\n",
       " '10ish',\n",
       " '10min',\n",
       " '10mins',\n",
       " '10minutes',\n",
       " '10pm',\n",
       " '10th',\n",
       " '10x',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '111',\n",
       " '111th',\n",
       " '112',\n",
       " '115th',\n",
       " '118',\n",
       " '11a',\n",
       " '11am',\n",
       " '11p',\n",
       " '11pm',\n",
       " '12',\n",
       " '120',\n",
       " '128i',\n",
       " '129',\n",
       " '12am',\n",
       " '12oz',\n",
       " '12pm',\n",
       " '12th',\n",
       " '13',\n",
       " '14',\n",
       " '140',\n",
       " '147',\n",
       " '14lbs',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '150mm',\n",
       " '15am',\n",
       " '15mins',\n",
       " '15pm',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '165',\n",
       " '169',\n",
       " '16th',\n",
       " '17',\n",
       " '17p',\n",
       " '18',\n",
       " '180',\n",
       " '18th',\n",
       " '19',\n",
       " '1900',\n",
       " '1913',\n",
       " '1928',\n",
       " '1929',\n",
       " '1930s',\n",
       " '1940',\n",
       " '1952',\n",
       " '1955',\n",
       " '1956',\n",
       " '1960',\n",
       " '1961',\n",
       " '1969',\n",
       " '1970',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1987',\n",
       " '1990s',\n",
       " '1992',\n",
       " '1995',\n",
       " '1996',\n",
       " '1998',\n",
       " '1999',\n",
       " '19th',\n",
       " '1cent',\n",
       " '1k',\n",
       " '1p',\n",
       " '1pm',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '200lbs',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '202',\n",
       " '20mbs',\n",
       " '20miles',\n",
       " '20min',\n",
       " '20pm',\n",
       " '20s',\n",
       " '20th',\n",
       " '20x',\n",
       " '21',\n",
       " '22',\n",
       " '220',\n",
       " '2240',\n",
       " '22oz',\n",
       " '23',\n",
       " '24',\n",
       " '24hrs',\n",
       " '24st',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '25b',\n",
       " '25min',\n",
       " '25th',\n",
       " '26',\n",
       " '260',\n",
       " '2600',\n",
       " '2608',\n",
       " '2669',\n",
       " '26th',\n",
       " '27',\n",
       " '272',\n",
       " '28',\n",
       " '29',\n",
       " '29th',\n",
       " '2am',\n",
       " '2mbps',\n",
       " '2nd',\n",
       " '2pm',\n",
       " '2rd',\n",
       " '2wice',\n",
       " '2x',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30am',\n",
       " '30p',\n",
       " '30pm',\n",
       " '30th',\n",
       " '31',\n",
       " '311',\n",
       " '312',\n",
       " '32',\n",
       " '33',\n",
       " '33rd',\n",
       " '34',\n",
       " '34th',\n",
       " '35',\n",
       " '350ib',\n",
       " '35c',\n",
       " '35th',\n",
       " '36',\n",
       " '37',\n",
       " '370',\n",
       " '38',\n",
       " '38th',\n",
       " '39',\n",
       " '3am',\n",
       " '3d',\n",
       " '3g',\n",
       " '3k',\n",
       " '3lbs',\n",
       " '3n9u549zse8up',\n",
       " '3p',\n",
       " '3pm',\n",
       " '3rd',\n",
       " '3x',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '40lm',\n",
       " '40min',\n",
       " '40th',\n",
       " '41',\n",
       " '411',\n",
       " '4113416766',\n",
       " '42',\n",
       " '420',\n",
       " '43',\n",
       " '44',\n",
       " '4458',\n",
       " '44th',\n",
       " '45',\n",
       " '453990',\n",
       " '45min',\n",
       " '45pm',\n",
       " '46',\n",
       " '475',\n",
       " '48',\n",
       " '480',\n",
       " '48th',\n",
       " '49',\n",
       " '490',\n",
       " '4b',\n",
       " '4hr',\n",
       " '4pm',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '50cents',\n",
       " '50lm',\n",
       " '50s',\n",
       " '51',\n",
       " '51pm',\n",
       " '52',\n",
       " '5231',\n",
       " '53',\n",
       " '53pm',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '59',\n",
       " '59th',\n",
       " '5k',\n",
       " '5min',\n",
       " '5p',\n",
       " '5pm',\n",
       " '5stars',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '602',\n",
       " '61',\n",
       " '61st',\n",
       " '62010',\n",
       " '623',\n",
       " '63',\n",
       " '64',\n",
       " '64th',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '680',\n",
       " '69',\n",
       " '6am',\n",
       " '6p',\n",
       " '6pm',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '70s',\n",
       " '70th',\n",
       " '71',\n",
       " '71st',\n",
       " '75',\n",
       " '750',\n",
       " '755891987',\n",
       " '76',\n",
       " '79',\n",
       " '7am',\n",
       " '7pm',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '8000hp',\n",
       " '80s',\n",
       " '81',\n",
       " '83',\n",
       " '832',\n",
       " '83rd',\n",
       " '85',\n",
       " '85154658',\n",
       " '86',\n",
       " '88',\n",
       " '89',\n",
       " '8am',\n",
       " '8pm',\n",
       " '8th',\n",
       " '8v',\n",
       " '8yo',\n",
       " '90',\n",
       " '90s',\n",
       " '91',\n",
       " '911',\n",
       " '945am',\n",
       " '95',\n",
       " '96',\n",
       " '977',\n",
       " '98',\n",
       " '99',\n",
       " '9999',\n",
       " '99cent',\n",
       " '9oz',\n",
       " '9p',\n",
       " '9pm',\n",
       " '9year',\n",
       " '9yo',\n",
       " '______',\n",
       " '_______________',\n",
       " '_c',\n",
       " '_gyib8ea4hdfylss17zc_g',\n",
       " 'a1',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaamazing',\n",
       " 'aaammmazzing',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abba',\n",
       " 'abbreviate',\n",
       " 'abbreviated',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abdomen',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abodoba',\n",
       " 'abound',\n",
       " 'abrasion',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'absent',\n",
       " 'absinthe',\n",
       " 'absoloutely',\n",
       " 'absolut',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'abstained',\n",
       " 'absurd',\n",
       " 'abuelo',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusive',\n",
       " 'ac',\n",
       " 'academy',\n",
       " 'acapulco',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessible',\n",
       " 'accessories',\n",
       " 'accessorize',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accommodations',\n",
       " 'accomodate',\n",
       " 'accomodating',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accoutrement',\n",
       " 'accredited',\n",
       " 'accross',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accustom',\n",
       " 'accustomed',\n",
       " 'accutemp',\n",
       " 'ace',\n",
       " 'ache',\n",
       " 'aches',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledging',\n",
       " 'ackward',\n",
       " 'acne',\n",
       " 'acoustic',\n",
       " 'acoustics',\n",
       " 'acquaintance',\n",
       " 'acres',\n",
       " 'acrid',\n",
       " 'acrimonious',\n",
       " 'acrylics',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activation',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activism',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'actully',\n",
       " 'acute',\n",
       " 'acy',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adamant',\n",
       " 'adams',\n",
       " 'adapter',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addictingly',\n",
       " 'addiction',\n",
       " 'addictionovercome',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'ade',\n",
       " 'adelman',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adios',\n",
       " 'adjacent',\n",
       " 'adjoining',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'administrative',\n",
       " 'admire',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admonishment',\n",
       " 'adobada',\n",
       " 'adobe',\n",
       " 'adobo',\n",
       " 'adolescence',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adoption',\n",
       " 'adoptions',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adorning',\n",
       " 'adovada',\n",
       " 'adquate',\n",
       " 'adrienne',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'adverts',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'aeg',\n",
       " 'aerators',\n",
       " 'aerobic',\n",
       " 'aerobics',\n",
       " 'aeropress',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affects',\n",
       " 'afficianados',\n",
       " 'affiliated',\n",
       " 'affiliation',\n",
       " 'affluent',\n",
       " 'afforadable',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afloat',\n",
       " 'aforementioned',\n",
       " 'afoul',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'afterall',\n",
       " 'afterdark',\n",
       " 'afterglow',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'agape',\n",
       " 'agave',\n",
       " 'agaves',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggressive',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'agua',\n",
       " 'aguas',\n",
       " 'agwa',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'ahi',\n",
       " 'ahold',\n",
       " 'ahwatukee',\n",
       " 'aid',\n",
       " 'aiello',\n",
       " 'aiko',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimlessly',\n",
       " 'aims',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'aioli',\n",
       " 'aiptasia',\n",
       " 'air',\n",
       " 'airconditioned',\n",
       " 'airfair',\n",
       " 'airfare',\n",
       " 'airline',\n",
       " 'airlines',\n",
       " 'airpark',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airwarys',\n",
       " 'airways',\n",
       " 'airy',\n",
       " 'aisha',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'aj',\n",
       " 'aji',\n",
       " 'ajo',\n",
       " 'ajos',\n",
       " 'ajs',\n",
       " 'ajvar',\n",
       " 'aka',\n",
       " 'aki',\n",
       " 'aknowledging',\n",
       " 'akor',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alain',\n",
       " 'alameda',\n",
       " 'alan',\n",
       " 'alarmed',\n",
       " 'alas',\n",
       " 'alaskan',\n",
       " 'alaus',\n",
       " 'albacore',\n",
       " 'albeit',\n",
       " 'alber',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'aldo',\n",
       " 'ale',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexandra',\n",
       " 'alfalfa',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'alfredo',\n",
       " 'algae',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'aliens',\n",
       " 'alike',\n",
       " 'alittle',\n",
       " 'alive',\n",
       " 'alla',\n",
       " 'allayed',\n",
       " 'alleged',\n",
       " 'allegiant',\n",
       " 'allen',\n",
       " 'allende',\n",
       " 'allergen',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'alleviated',\n",
       " 'alley',\n",
       " 'alligator',\n",
       " 'allocating',\n",
       " 'allot',\n",
       " 'alloted',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allure',\n",
       " 'almond',\n",
       " 'almonds',\n",
       " 'aloe',\n",
       " 'alofts',\n",
       " 'aloha',\n",
       " 'alongside',\n",
       " 'alons',\n",
       " 'aloo',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alp',\n",
       " 'alright',\n",
       " 'alteration',\n",
       " 'alterations',\n",
       " 'altercation',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternately',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'altic',\n",
       " 'aluminum',\n",
       " 'alway',\n",
       " 'ama',\n",
       " 'amaaaaazing',\n",
       " 'amaazing',\n",
       " 'amados',\n",
       " 'amalfi',\n",
       " 'amanda',\n",
       " 'amaretti',\n",
       " 'amaretto',\n",
       " 'amarillo',\n",
       " 'amaro',\n",
       " 'amateur',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazingness',\n",
       " 'amazon',\n",
       " 'amazzzzzzing',\n",
       " 'ambassador',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'ambient',\n",
       " 'ambrosia',\n",
       " 'amc',\n",
       " 'amenable',\n",
       " 'amendment',\n",
       " 'amenities',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americanized',\n",
       " 'americano',\n",
       " 'americanos',\n",
       " 'americans',\n",
       " 'ami',\n",
       " 'amicable',\n",
       " 'amidst',\n",
       " 'amin',\n",
       " 'amish',\n",
       " 'ammo',\n",
       " 'amomi',\n",
       " 'amore',\n",
       " 'amounted',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'amphitheatre',\n",
       " 'ample',\n",
       " 'ampm',\n",
       " 'amtrack',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'anal',\n",
       " 'analysis',\n",
       " 'ancho',\n",
       " 'anchor',\n",
       " 'anchors',\n",
       " 'anchovies',\n",
       " 'anchovy',\n",
       " 'andiamo',\n",
       " 'andouille',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'andy',\n",
       " 'anecdotes',\n",
       " 'anemic',\n",
       " 'anesthetic',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelic',\n",
       " 'angello',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'anglaise',\n",
       " 'angle',\n",
       " 'angler',\n",
       " 'angles',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'anibal',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animatronics',\n",
       " 'anise',\n",
       " 'aniston',\n",
       " 'ankle',\n",
       " 'ankles',\n",
       " 'ann',\n",
       " 'anne',\n",
       " 'annie',\n",
       " 'annihilator',\n",
       " 'anniversary',\n",
       " 'announced',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'anomaly',\n",
       " 'anonymous',\n",
       " 'ans',\n",
       " 'ansel',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'anthem',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'antipasti',\n",
       " 'antipasto',\n",
       " 'antique',\n",
       " 'antiques',\n",
       " 'antiquing',\n",
       " 'antiseptic',\n",
       " 'antithesis',\n",
       " 'antler',\n",
       " 'antonio',\n",
       " 'antono',\n",
       " 'ants',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'anybody',\n",
       " 'anyday',\n",
       " 'anyhoo',\n",
       " 'anymore',\n",
       " 'anyplace',\n",
       " 'anythings',\n",
       " 'anytime',\n",
       " 'anyways',\n",
       " 'anywho',\n",
       " 'ao',\n",
       " 'ap',\n",
       " 'apache',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apartments',\n",
       " 'ape',\n",
       " 'apiece',\n",
       " 'apologetic',\n",
       " 'apologetically',\n",
       " 'apologists',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'apologizes',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'apostles',\n",
       " 'apothecary',\n",
       " 'apothic',\n",
       " 'app',\n",
       " 'appalachians',\n",
       " 'appaled',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'apparantly',\n",
       " 'apparel',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appauling',\n",
       " 'appeal',\n",
       " 'appealed',\n",
       " 'appealing',\n",
       " 'appeals',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appeasing',\n",
       " 'appertizer',\n",
       " 'appetit',\n",
       " 'appetite',\n",
       " 'appetito',\n",
       " 'appetizaer',\n",
       " 'appetizer',\n",
       " 'appetizers',\n",
       " 'appetizing',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'applebee',\n",
       " 'applebees',\n",
       " 'apples',\n",
       " 'appletini',\n",
       " 'appletinis',\n",
       " 'appliances',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appoinmtnt',\n",
       " 'appointed',\n",
       " 'appointment',\n",
       " 'appointments',\n",
       " 'appologized',\n",
       " 'appraisal',\n",
       " 'appraisals',\n",
       " 'appraiser',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'apprehensive',\n",
       " 'appreicate',\n",
       " 'approach',\n",
       " 'approachable',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approx',\n",
       " 'approximate',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'appt',\n",
       " 'appys',\n",
       " 'apricot',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'apt',\n",
       " 'aqua',\n",
       " 'aquarium',\n",
       " 'aquiring',\n",
       " 'ar',\n",
       " 'arabic',\n",
       " 'arai',\n",
       " 'arbol',\n",
       " 'arboreal',\n",
       " 'arborio',\n",
       " 'arcade',\n",
       " 'arcadia',\n",
       " 'arcane',\n",
       " 'arches',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " 'archive',\n",
       " 'archway',\n",
       " 'arco',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arena',\n",
       " 'arent',\n",
       " 'argentine',\n",
       " 'argue',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'argumentative',\n",
       " 'argyle',\n",
       " 'ariel',\n",
       " 'arigato',\n",
       " 'arise',\n",
       " 'arizona',\n",
       " 'arizonan',\n",
       " 'arizonans',\n",
       " 'arkansas',\n",
       " 'arlecchino',\n",
       " 'arm',\n",
       " 'armando',\n",
       " 'armed',\n",
       " 'armour',\n",
       " 'arms',\n",
       " 'army',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3064x16528 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 143743 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Use multinomial Naive Bayes to **predict the star rating** for the reviews in the testing set, and then **calculate the accuracy** and **print the confusion matrix**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9158512720156555"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124,  60],\n",
       "       [ 26, 812]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(set(y_test))\n",
    "labels\n",
    "#labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    5\n",
       "1  124   60\n",
       "5   26  812"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    data=metrics.confusion_matrix(y_test, y_pred_class, labels=labels),\n",
    "    columns=labels,\n",
    "    index=labels\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Calculate the **null accuracy**, which is the classification accuracy that could be achieved by always predicting the most frequent class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    838\n",
       "1    184\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.99608610567515"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test.value_counts().values.tolist()[0]/sum(y_test.value_counts().values.tolist()))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Browse through the review text of some of the **false positives** and **false negatives**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2175    This has to be the worst restaurant in terms o...\n",
       "1781    If you like the stuck up Scottsdale vibe this ...\n",
       "995     Not worth the money. Food was average and the ...\n",
       "3392    I found Lisa G's while driving through phoenix...\n",
       "8283    Don't know where I should start. Grand opening...\n",
       "2765    Went last week, and ordered a dozen variety. I...\n",
       "2839    Never Again,\\r\\nI brought my Mountain Bike in ...\n",
       "1423    I hadn't been to Fuddruckers for about 20 year...\n",
       "321     My wife and I live around the corner, hadn't e...\n",
       "1919                                         D-scust-ing.\n",
       "2490    Lazy Q CLOSED in 2010.  New Owners cleaned up ...\n",
       "6916    Brought a group to Metro for brunch, made the ...\n",
       "8755    Not lesbian/gay friendly at all. I should have...\n",
       "9125    La Grande Orange Grocery has a problem. It can...\n",
       "7380    I keep wanting to like this place.  I want to ...\n",
       "9185    For frozen yogurt quality, I give this place a...\n",
       "436     this another place that i would give no stars ...\n",
       "2051    Sadly with new owners comes changes on menu.  ...\n",
       "89      I was really excited about this event, maybe m...\n",
       "1721    This is the closest to a New York hipster styl...\n",
       "842     Boy is the name a temptation.Seriously :)  I'l...\n",
       "943     Don't waste your time...Arrowhead mall on the ...\n",
       "5977    You want good food? You'd be better off smuggl...\n",
       "8833    The owner has changed hands & this place isn't...\n",
       "6584    Jimmy Johns is cheaper and better ... The Capr...\n",
       "1899    Buca Di Beppo is literally, italian restaurant...\n",
       "9953    \"Hipster,Trendy\" ????-I think NOT !!!! Very di...\n",
       "2060                This place is closed.  Good riddance.\n",
       "3082    Currently having a liquidation sale, but it's ...\n",
       "8220    Maybe I ate at a different restaurant than the...\n",
       "2430    Just because this place is called \"Maria Maria...\n",
       "3634    Seriously?! With grocery stores like Fresh & E...\n",
       "3266    Absolutely awful... these guys have NO idea wh...\n",
       "7397    This place sucks!! I moved to the valley and h...\n",
       "4473    It is what you would expect from any themed pl...\n",
       "5502    Angry Bro Bar !  Please go here if you wear si...\n",
       "2615    Great in its day, now leaves a lot to be desir...\n",
       "3413    I purchased the Enotria groupon when it was re...\n",
       "287     First, I hope La Fonda management reads these ...\n",
       "2999    I can't even believe I actually went to this r...\n",
       "1372    No offense to everyone who gave this place 5 s...\n",
       "6222    My mother always told me, if I didn't have any...\n",
       "9296    My boyfriend and I tried this place last year ...\n",
       "2333    Not only was the music the worst I have ever h...\n",
       "7975    What are you all talking about?! This place is...\n",
       "4630    I used to always go here for tires until my me...\n",
       "7130    I was not impressed. The food was bad & expens...\n",
       "5818    Most horrible buffet I have ever been to.\\r\\n\\...\n",
       "3704    Staff is nice, and that's it.\\r\\nThey use very...\n",
       "8741    They served us stale rice.  Average main dishe...\n",
       "3938    We were so disappointed!  We were on vacation ...\n",
       "8681    As I promised myself, I'd go back again to try...\n",
       "1532    Cold, under done chips. If a Mexican food rest...\n",
       "113     Unless you are a regular or look like your wal...\n",
       "9299    The salad plates were not chilled... As they u...\n",
       "4311    Donuts are really good, if they have any when ...\n",
       "7035    Totally excited to try this place out, my gran...\n",
       "8000    Still a place that is unacceptable in my book-...\n",
       "3755    Have been going to LGO since 2003 and have alw...\n",
       "507     HELLISH HELLISH SUMMER WEATHER (March thru Oct...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#false positives\n",
    "X_test[(y_test==1) & (y_pred_class==5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7148    I now consider myself an Arizonian. If you dri...\n",
       "4963    This is by far my favourite department store, ...\n",
       "6318    Since I have ranted recently on poor customer ...\n",
       "380     This is a must try for any Mani Pedi fan. I us...\n",
       "5565    I`ve had work done by this shop a few times th...\n",
       "3448    I was there last week with my sisters and whil...\n",
       "6050    I went to sears today to check on a layaway th...\n",
       "2504    I've passed by prestige nails in walmart 100s ...\n",
       "2475    This place is so great! I am a nanny and had t...\n",
       "241     I was sad to come back to lai lai's and they n...\n",
       "3149    I was told to see Greg after a local shop diag...\n",
       "423     These guys helped me out with my rear windshie...\n",
       "763     Here's the deal. I said I was done with OT, bu...\n",
       "5805    One of our Lexus car keys/key fob was cracked ...\n",
       "8956    I took my computer to RedSeven recently when m...\n",
       "750     This store has the most pleasant employees of ...\n",
       "9765    You can't give anything less than 5 stars to a...\n",
       "4646    Wow, I am very impressed. The store is very bi...\n",
       "9622    I always buy my tires at Walmart, but they did...\n",
       "6334    I came here today for a manicure and pedicure....\n",
       "1282    Loved my haircut. Walked in and waited for jus...\n",
       "1266    I've never been to this location before. My hu...\n",
       "402     Once again Wildflower proves why it's my favor...\n",
       "3635    I love Coach.\\r\\nStylish and trendy without sp...\n",
       "2494    What a great surprise stumbling across this ba...\n",
       "7903    First, I'm sorry this review is lengthy, but i...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#false negatives\n",
    "X_test[(y_test==5) & (y_pred_class==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Calculate which 10 tokens are the most predictive of **5-star reviews**, and which 10 tokens are the most predictive of **1-star reviews**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16528"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '00a', '00am', '00pm', '01', '02', '03', '03342', '04', '05', '06', '07', '09', '0buxoc0crqjpvkezo3bqog', '0l', '10', '100', '1000', '1000x', '1001', '100th', '101', '102', '105', '1070', '108', '10am', '10ish', '10min', '10mins', '10minutes', '10pm', '10th', '10x', '11', '110', '1100', '111', '111th', '112', '115th', '118', '11a', '11am', '11p', '11pm', '12', '120', '128i']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yyyyy', 'z11', 'za', 'zabba', 'zach', 'zam', 'zanella', 'zankou', 'zappos', 'zatsiki', 'zen', 'zero', 'zest', 'zexperience', 'zha', 'zhou', 'zia', 'zihuatenejo', 'zilch', 'zin', 'zinburger', 'zinburgergeist', 'zinc', 'zinfandel', 'zing', 'zip', 'zipcar', 'zipper', 'zippers', 'zipps', 'ziti', 'zoe', 'zombi', 'zombies', 'zone', 'zones', 'zoning', 'zoo', 'zoyo', 'zucca', 'zucchini', 'zuchinni', 'zumba', 'zupa', 'zuzu', 'zwiebel', 'zzed', 'éclairs', 'école', 'ém']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.,  4.,  1., ...,  0.,  0.,  0.],\n",
       "       [39.,  5.,  0., ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16528)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26.,  4.,  1., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_star_count = nb.feature_count_[0, :]\n",
    "one_star_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39.,  5.,  0., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_star_count = nb.feature_count_[1, :]\n",
    "five_star_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-star</th>\n",
       "      <th>5-star</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zucchini</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuchinni</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zumba</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zupa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuzu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwiebel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>éclairs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>école</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ém</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1-star  5-star\n",
       "token                   \n",
       "zucchini     1.0    10.0\n",
       "zuchinni     1.0     1.0\n",
       "zumba        0.0     3.0\n",
       "zupa         0.0     1.0\n",
       "zuzu         0.0     3.0\n",
       "zwiebel      0.0     1.0\n",
       "zzed         0.0     1.0\n",
       "éclairs      0.0     1.0\n",
       "école        0.0     1.0\n",
       "ém           0.0     1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = pd.DataFrame({'token':X_train_tokens, '1-star':one_star_count, '5-star':five_star_count}).set_index('token')\n",
    "tokens.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
